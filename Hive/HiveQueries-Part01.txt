// BIG DATA ANALYSIS - HIVE COMMANDS
// AUTHOR: MARTAND SINGH
// EMAIL: martandsays@gmail.com
// FACEBOOK: https://www.facebook.com/codemakerz
// WANT TO PARTICIPATE? CONTACT US ANYTIME.

// GET THE LIST OF DATABASES 
show databases;

// USE A DATABASE
use sample_db;

// GET THE DETAILS ABOUT DATABASE
describe database sample_db;

// GET MORE GRANULAR DETAILS ABOUT DATABASE
describe database extended sample_db;

// DROP A DATABASE
drop database sample_db;

// DROP DATABASE WITH EXISTING TABLES
drop database sample_db CASCADE;

// CREATE A DATABASE WITH EXTRA PROPERTIES
create database if not exists sample_db
    > comment "sample database for CCA Data Analyst"
    > location "/user/sample"
    > with DBPROPERTIES(
    > 'Date'='01-June-2020',
    > 'City'='Dubai');


// SHOW DATABASE AS REGEX - IT WILL SHOW ALL THE DATABASE WHICH STARTS WITH THE NAME 'sam' e.g. sample_db;
show databases like 'sam*';


// CREATE A MANAGED TABLE - A MANAGED TABLE MOVES THE DATA FROM ORIGINAL HADOOP LOCATION TO THE HIVE DATAWAREHOUSE LOCATION. 
// IF YOU DROP A MANAGED TABLE, IT WILL DELETE THE METADATA & DATA FILES ALSO.
// FIELDS TERMINATED BY - HOW YOUR COLUMNS ARE SEPERATED. IN MY CASE I AM USING A CSV, SO ','
// LINES TERMINATED BY - HOW LINES ARE TERMINATED. IN MY CASE '\n'. THIS IS DEFAULT VALUE.
// COMMENTS - SIMPLY PLAIN TEXT OR COMMENT.
// STORED AS TEXTFILE - HOW YOU DATA WILL BE STORED IN HDFS. ORC, TEXTFILE, PARQUET.

CREATE TABLE sales_record
(
Region STRING,
Country STRING,
ItemType STRING,
SalesChannel STRING,
OrderPriority STRING,
OrderDate STRING,
OrderID STRING,
ShipDate STRING,
UnitsSold INT,
UnitPrice FLOAT,
UnitCost FLOAT,
TotalRevenue FLOAT,
TotalCost FLOAT,
TotalProfit FLOAT
)
COMMENT 'Sales record hive table'
ROW FORMAT DELIMITED
FIELDS TERMINATED BY ','
LINES TERMINATED BY '\n'
STORED AS TEXTFILE;


// TO IMPORT DATA IN HIVE TABLE, FIRST YOU HAVE TO COPY DATA FROM LOCAL FILE SYSTEM TO HDFS.
// DATA FILE AVAILABLE AT: https://github.com/martandsingh/BigDataAnalytics/tree/main/dataset
// I AM USING SalesRecords.csv FOR MY EXAMPLE.

hadoop fs -copyFromLocal /home/cloudera/dataset/salesdata.csv /user/cloudera/msingh
 
// LOADING DATA FROM HDFS FILE (WHICH WE COPIED IN ABOVE STEP) TO HIVE TABLE. AFTER RUNNING THIS STEP, YOUR ORIGINAL FILES WILL BE MOVED TO HIVE
// WAREHOUSE LOCATION. IN MY CASE /user/hive/warehouse

LOAD DATA INPATH '/user/cloudera/msingh/salesdata.csv' OVERWRITE INTO TABLE sales_record;

// CHECK ORIGINAL FILE. IT SHOULD NOT BE THERE.
hadoop fs -ls /user/hive/warehouse



// SO NOW WE HAVE TO COPY OUR DATA TO HDFS. SO WE WILL CREATE A NEW FOLDER IN OUR HDFS LOCATION & ADD FILE TO IT.
hadoop fs -copyFromLocal /home/cloudera/dataset/salesdata.csv /user/cloudera/msingh/salesdb
hadoop fs -mkdir /user/cloudera/msingh/salesdb


// EXTERNAL TABLE - TO CREATE EXTERNAL TABLE JUST ADD EXTERNAL KEYWORD. EXTERNAL TABLE DOES NOT MOVE ORIGINAL DATA FILES TO THE HIVE DATAWAREHOUSE LOCATION.
// IF YOU DROP EXTERNAL TABLE, IT WILL ONLY DELETE THE HIVE METADATA. DATA WILL NOT BE AFFECTED OR DELETED.
// IN EXTERNAL TABLE, WE DO NOT HAVE TO LOAD THE DATA. WE WILL SIMPLY PROVIDE THE HDFS LOCATION OF THE DATA FILES & OUR HIVE TABLE WILL POINT
// THAT LOCATION. PAY ATTENTION TO THE LOCATION PROPERTY HERE. WE ARE NOT PROVIDING THE FILE NAME, WE ARE PROVIDING THE FOLDER WHERE FILE IS LOCATED.
// THIS IS IMPORTANT TO NOTE.

CREATE EXTERNAL TABLE sales_record_ext
(
Region STRING,
Country STRING,
ItemType STRING,
SalesChannel STRING,
OrderPriority STRING,
OrderDate STRING,
OrderID STRING,
ShipDate STRING,
UnitsSold INT,
UnitPrice FLOAT,
UnitCost FLOAT,
TotalRevenue FLOAT,
TotalCost FLOAT,
TotalProfit FLOAT
)
COMMENT 'Sales record hive table'
ROW FORMAT DELIMITED
FIELDS TERMINATED BY ','
LINES TERMINATED BY '\n'
STORED AS TEXTFILE
LOCATION '/user/cloudera/msingh/salesdb';

// CHECK TOP 10 RECORDS FOR THE NEW EXTERNAL TABLE CREATED
SELECT * FROM sales_record_ext LIMIT 10;

// SO NOW IF YOU WILL DROP THIS TABLE,IT WILL NOT AFFECT YOUR DATA FILES. BASICALLY NOW THIS HIVE TABLE IS REFERENCING YOUR DATA FILES AT GIVEN LOCATION

// GET DETAILS ABOUT TABLE
describe sales_record;

// GET GRANULAR DETAILS ABOUT TABLE
describe  formatted  sales_record;


// CHECK TOP 10 RECORDS 
select * from sales_record limit 10;

//CHECK COLUMN NAMES
describe database.tablename;


// TILL NOW WE LOADED DATA FROM HDFS. LETS SAY WE WANT TO LOAD DATA FORM OUT LOCAL SYSTEM TO HIVE TABLE.
// WE WILL CREATE ONE EXTERNAL TABLE WITHOUT LOCATION PROPERTY. 
CREATE EXTERNAL TABLE sales_record_ext_local
(
Region STRING,
Country STRING,
ItemType STRING,
SalesChannel STRING,
OrderPriority STRING,
OrderDate STRING,
OrderID STRING,
ShipDate STRING,
UnitsSold INT,
UnitPrice FLOAT,
UnitCost FLOAT,
TotalRevenue FLOAT,
TotalCost FLOAT,
TotalProfit FLOAT
)
COMMENT 'Sales record hive table'
ROW FORMAT DELIMITED
FIELDS TERMINATED BY ','
LINES TERMINATED BY '\n'
STORED AS TEXTFILE;

// IT IS SAME COMMAND AS BEFORE BUT WE ADDED ONE EXTRA KEYWORD 'LOCAL'. SO THIS COMMAND WILL NOT COPY YOUR DATA FILE(S) TO HDFS. IT WILL USE DIRECTLY 
// FROM THE GIVEN LOCATION INSTEAD.
LOAD DATA LOCAL INPATH '/home/cloudera/dataset/salesdata.csv' OVERWRITE INTO TABLE sales_record_ext_local;


